from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
import os

class CriticAgent:
    """
    Reviewer agent that validates the Analyst's code BEFORE execution.
    It checks for:
    1. Alignment with user question (e.g. correct year, correct filters).
    2. Safety (no dangerous commands).
    3. Completeness (uses print to show results).
    """
    def __init__(self, model_name="gemini-2.5-flash"):
        api_key = os.getenv("GOOGLE_API_KEY") # Ensure this is set!
        # Convert to Gemini
        self.llm = ChatGoogleGenerativeAI(model=model_name, temperature=0, google_api_key=api_key)
        self.prompt = self._build_prompt()

    def _build_prompt(self):
        system_instructions = """
You are a Senior Code Reviewer for a Public Audit AI.
Your goal is to critique Python code generated by a Data Analyst.

INPUT:
1. User Question: The original question from the user.
2. Generated Code: The python code to be executed.

CHECKLIST:
1. **Logic**: Does the code answer the SPECIFIC question? 
   - Check filters! (e.g. if user asked for "2024", is there `WHERE exercicio_orcamento='2024'`?)
   - Check aggregation! (e.g. `sum` vs `count`)
2. **Safety**: Are there any dangerous commands? (e.g. `os.system`, `drop table`).
3. **Completeness**: Does it print the final answer?

OUTPUT FORMAT:
- If the code is GOOD: Respond with "APPROVE".
- If the code is BAD: Respond with "REJECT: <explanation of what is wrong>".
"""
        return ChatPromptTemplate.from_messages([
            ("system", system_instructions),
            ("user", "User Question: {question}\n\nGenerated Code:\n```python\n{code}\n```")
        ])

    def review_code(self, question: str, code: str) -> str:
        chain = self.prompt | self.llm
        response = chain.invoke({"question": question, "code": code})
        return response.content.strip()
